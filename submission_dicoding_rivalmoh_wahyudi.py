# -*- coding: utf-8 -*-
"""Submission_Dicoding_RivalMoh.Wahyudi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uXRCLwpf80BtNsYUvYtpVjv9MpAvynE3
"""

import tensorflow as tf
print(tf.__version__)

pip install split-folders

"""# mempersiapkan Data set"""

!wget --no-check-certificate https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip -O /tmp/rockpaperscissors.zip

# melakukan ekstraksi pada file zip
import zipfile,os
import splitfolders

local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

splitfolders.ratio('/tmp/rockpaperscissors/rps-cv-images', output="/tmp/rockpaperscissors/", seed=1337, ratio=(.8, .2))
splitfolders.fixed('/tmp/rockpaperscissors/rps-cv-images', output="/tmp/rockpaperscissors/", seed=1337, fixed=(100, 100), oversample=False)

base_dir = '/tmp/rockpaperscissors'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')

path = os.listdir('/tmp/rockpaperscissors/scissors')
path1 = os.listdir('/tmp/rockpaperscissors/paper')
path2 = os.listdir('/tmp/rockpaperscissors/rock')
print (len(path))
print (len(path1))
print (len(path2))

training_rock_dir = os.path.join(train_dir, 'rock')
training_paper_dir = os.path.join(train_dir, 'paper')
training_scissors_dir = os.path.join(train_dir, 'scissors')

val_rock_dir = os.path.join(validation_dir, 'rock')
val_paper_dir = os.path.join(validation_dir, 'paper')
val_scissors_dir = os.path.join(validation_dir, 'scissors')

rock_img = os.listdir(training_rock_dir)
paper_img = os.listdir(training_paper_dir)
scissors_img = os.listdir(training_scissors_dir)

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

plt.figure(figsize=(22, 5))
for i, img_path in enumerate(paper_img[:5]):
    sp = plt.subplot(1, 5, i+1)
    img = mpimg.imread(os.path.join(training_paper_dir, img_path))
    plt.imshow(img)
plt.show()

plt.figure(figsize=(22, 5))
for i, img_path in enumerate(rock_img[:5]):
    sp = plt.subplot(1, 5, i+1)
    img = mpimg.imread(os.path.join(training_rock_dir, img_path))
    plt.imshow(img)
plt.show()

plt.figure(figsize=(22, 5))
for i, img_path in enumerate(scissors_img[:5]):
    sp = plt.subplot(1, 5, i+1)
    img = mpimg.imread(os.path.join(training_scissors_dir, img_path))
    plt.imshow(img)
plt.show()

"""# Augmentasi image"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale= 1./255, validation_split= 0.4, shear_range = 0.2, zoom_range= 0.2, rotation_range= 20, horizontal_flip=True)
validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.6)

train_generator = train_datagen.flow_from_directory(
            train_dir,
            target_size=(100,100),
            batch_size=32,
            class_mode='categorical',
            shuffle=True
)

valid_generator = validation_datagen.flow_from_directory(
            validation_dir,
            target_size=(100,100),
            batch_size=32,
            class_mode='categorical',
            shuffle=True,
            subset='validation'
)

train_generator.class_indices

valid_generator.class_indices

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv2D, Activation, Flatten, MaxPool2D
from tensorflow.keras.optimizers import Adam, RMSprop

model = Sequential()

model.add(Conv2D(16, kernel_size=3, activation='relu', input_shape=(100, 100, 3)))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Conv2D(32, kernel_size=3, activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Conv2D(64, kernel_size=3, activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Conv2D(128, kernel_size=3, activation='relu'))
model.add(MaxPool2D(2,2))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(512, activation='relu'))
model.add(Dense(3, activation='softmax'))

model.summary()

model.compile(optimizer = 'RMSprop',
              loss = 'categorical_crossentropy',
              metrics = ['accuracy'])

model.fit(
    train_generator,
    steps_per_epoch = 32,
    epochs = 20,
    validation_data = valid_generator,
    validation_steps = 5,
    verbose = 2
)

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():


  path = fn
  img = image.load_img(path, target_size=(100,100))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=32)

  print(fn)
  if classes[0,0] == 1.0:
    print('Paper')
  elif classes[0,1] == 1.0:
    print('Rock')
  else:
    print('Scissors')